"""
Configura√ß√£o centralizada para o MVP de Terapia Familiar
"""

import os
from crewai import LLM
import logging

# Tentar carregar .env para desenvolvimento local
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # dotenv n√£o dispon√≠vel - isso √© normal no Streamlit Cloud
    pass

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Config:
    """Classe de configura√ß√£o centralizada"""
    
    # API Keys
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-fake-key-for-crewai-validation-only")
    
    # Configura√ß√µes do LLM
    MODEL = os.getenv("MODEL", "gemini/gemini-1.5-flash")
    LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.7"))
    LLM_MAX_TOKENS = int(os.getenv("LLM_MAX_TOKENS", "2048"))
    
    # Configura√ß√µes da aplica√ß√£o
    APP_TITLE = os.getenv("APP_TITLE", "Terapia Familiar MVP")
    APP_DESCRIPTION = os.getenv("APP_DESCRIPTION", "Sistema de apoio emocional baseado em Carter & McGoldrick")
    
    # Configura√ß√µes de Mem√≥ria CrewAI
    ENABLE_MEMORY = os.getenv("ENABLE_MEMORY", "false").lower() == "true"  # Desabilitado temporariamente
    MEMORY_PROVIDER = os.getenv("MEMORY_PROVIDER", "local")
    MEMORY_DIR = os.getenv("MEMORY_DIR", "./crew_memory")
    
    # Para Cloud Run
    PORT = int(os.getenv("PORT", 8080))
    
    # Configura√ß√µes de Debug
    DEBUG = os.getenv("DEBUG", "false").lower() == "true"
    VERBOSE = os.getenv("VERBOSE", "true").lower() == "true"
    
    @classmethod
    def get_llm(cls, temperature: float = None) -> LLM:
        """Retorna uma inst√¢ncia configurada do LLM usando CrewAI"""
        
        # Configurar vari√°veis de ambiente necess√°rias
        os.environ["GEMINI_API_KEY"] = cls.GEMINI_API_KEY
        os.environ["OPENAI_API_KEY"] = cls.OPENAI_API_KEY
        
        llm = LLM(
            model=cls.MODEL,
            temperature=temperature or cls.LLM_TEMPERATURE,
        )
        
        logger.info(f"‚úÖ LLM configurado: {cls.MODEL}")
        return llm
    
    @classmethod
    def validate_config(cls):
        """Valida se todas as configura√ß√µes necess√°rias est√£o presentes"""
        
        if not cls.GEMINI_API_KEY:
            # Mensagem mais informativa para deployment
            error_msg = """
‚ùå GEMINI_API_KEY n√£o configurada!

Para configurar no Streamlit Cloud:
1. V√° para https://share.streamlit.io
2. Clique em 'Settings' do seu app
3. Na aba 'Secrets', adicione:
   GEMINI_API_KEY = "sua_chave_aqui"

Para desenvolvimento local:
1. Crie um arquivo .env
2. Adicione: GEMINI_API_KEY=sua_chave_aqui
            """
            raise ValueError(error_msg.strip())
        
        logger.info("‚úÖ Configura√ß√£o validada com sucesso")
        logger.info(f"üì± Modelo: {cls.MODEL}")
        logger.info(f"üå°Ô∏è Temperature: {cls.LLM_TEMPERATURE}")
        logger.info(f"üß† Mem√≥ria: {cls.ENABLE_MEMORY}")
        logger.info(f"üîç Debug: {cls.DEBUG}")
        
        return True
